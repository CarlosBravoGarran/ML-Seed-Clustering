{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlos Bravo GarrÃ¡n - 100474964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Seed Clustering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1. Load the dataset__\n",
    "\n",
    "Load the seed dataset from a CSV file. \n",
    "\n",
    "The features are stored in `X`, and the target class labels are stored in `y`.\n",
    "\n",
    "Add seed variable for random states (`100474964`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/semillas.csv')\n",
    "X = data.drop(columns=['clase'])\n",
    "y = data['clase']\n",
    "\n",
    "seed = 100474964\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2. Comparison of Scalers__\n",
    "\n",
    "In this section, we aim to identify the most appropriate scaler for the seed dataset before applying clustering algorithms. Scaling is crucial to ensure that all features contribute equally to the distance calculations.\n",
    "\n",
    "We compare three scalers:\n",
    "- MinMaxScaler\n",
    "- RobustScaler\n",
    "- StandardScaler\n",
    "\n",
    "The scaled data is projected into 2D using PCA for visual evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'StandardScaler': StandardScaler()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, (name, scaler) in enumerate(scalers.items(), 1):\n",
    "    pipeline = make_pipeline(scaler, PCA(n_components=2, random_state=seed))\n",
    "    \n",
    "    X_pca = pipeline.fit_transform(X)\n",
    "    \n",
    "    plt.subplot(1, 3, i)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', alpha=0.7, s=50)\n",
    "    plt.title(f'{name} + PCA (By class)')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.suptitle('Comparison of Scalers with PCA (By Seed Class)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Best Scaler Selection\n",
    "\n",
    "After observing the PCA plots:\n",
    "\n",
    "- **MinMaxScaler**: The data points are well distributed with moderate separation between different seed classes. Although some overlap exists, the distribution appears balanced and suitable for clustering.\n",
    "- **RobustScaler**: There is a good separation of classes, but the spread of the data is larger, which may not be ideal for density-based methods.\n",
    "- **StandardScaler**: While resistant to outliers, the classes are not well separated, making clustering more difficult.\n",
    "\n",
    "We select **MinMaxScaler** because it provides a balanced and homogeneous distribution of the data, facilitating the identification of clusters without introducing large variations in scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Variance Explained by PCA\n",
    "\n",
    "To ensure that the 2D projection using PCA retains enough information from the original dataset, we calculate the total variance explained by the two principal components after applying each scaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_ratios = {}\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    variance_explained = np.sum(pca.explained_variance_ratio_)\n",
    "    variance_ratios[name] = variance_explained\n",
    "    \n",
    "    print(f'{name}: Variance explained by 2 components = {variance_explained:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that all three scalers achieve a high variance explanation (>85%), indicating that the 2D PCA projection is representative of the original dataset in every case.\n",
    "\n",
    "Among them, **MinMaxScaler** achieves the highest variance explained, with 91.81%.\n",
    "\n",
    "We confirm that using **MinMaxScaler** is appropriate, as it retains the largest proportion of the original data variance after dimensionality reduction. Therefore, we proceed with MinMaxScaler for the clustering tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
